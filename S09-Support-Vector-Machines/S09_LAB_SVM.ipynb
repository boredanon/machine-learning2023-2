{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/boredanon/machine-learning2023-2/blob/main/S09-Support-Vector-Machines/S09_LAB_SVM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Nombre:** José del Solar Zavala\n",
        "\n",
        "**Fecha:** 20/10/23\n",
        "\n",
        "**Módulo:** Machine Learning\n"
      ],
      "metadata": {
        "id": "wQBmx2y979hF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Enunciado: Laboratorio de Máquinas de Soporte Vectorial en Python\n",
        "\n",
        "## Objetivo\n",
        "El objetivo de este laboratorio es experimentar con un conjunto de datos artificial que sigue una distribución Gaussiana creada por el programador. Utilizaremos el kernel Gaussiano para aprender la estructura utilizando máquinas de Soporte Vectorial.\n",
        "\n",
        "\n",
        "## Etapas Metodológicas\n",
        "\n",
        "Se deben seguir las siguientes cinco etapas metodológicas:\n",
        "\n",
        "1. **Obtención de datos**: Generar un conjunto de datos artificial siguiendo una distribución Gaussiana.\n",
        "\n",
        "2. **Manipulación**: Dividir el conjunto de datos en conjuntos de entrenamiento, prueba y validación.\n",
        "\n",
        "3. **Exploración**: Visualizar los datos para entender la distribución y la relación entre las categorías.\n",
        "\n",
        "4. **Modelamiento**: Implementar un clasificador de Máquinas de Soporte Vectorial utilizando el kernel Gaussiano.\n",
        "\n",
        "5. **Interpretación**: Analizar y discutir los resultados obtenidos, incluyendo las estadísticas de clasificación y los parámetros ajustados.\n",
        "\n",
        "## Instrucciones\n",
        "\n",
        "1. Crea un Jupyter notebook para llevar a cabo el laboratorio.\n",
        "\n",
        "2. Genera un conjunto de datos artificial que siga una distribución Gaussiana concéntrica.\n",
        "\n",
        "3. Divide el conjunto de datos en conjuntos de entrenamiento, prueba y validación.\n",
        "\n",
        "4. Grafica los conjuntos de datos, asignando el color rojo a una categoría y el color azul a la otra.\n",
        "\n",
        "5. Entrena un clasificador de Máquinas de Soporte Vectorial utilizando el kernel Gaussiano.\n",
        "\n",
        "6. Muestra las estadísticas de clasificación (precisión, recall, F1-score, etc.).\n",
        "\n",
        "7. Realiza ajustes en los parámetros del clasificador y documenta los cambios en el rendimiento.\n",
        "\n",
        "8. Interpreta los resultados y concluye sobre la eficacia del modelo.\n",
        "\n",
        "9. Entrega el Jupyter notebook con todos los pasos y explicaciones detalladas.\n",
        "\n",
        "Recuerda documentar cada paso y proporcionar explicaciones claras y concisas en tu notebook. ¡Buena suerte!\n",
        "\n",
        "plt.title(\"Gaussian divided into three quantiles\", fontsize=\"small\")\n",
        "X1, Y1 = make_gaussian_quantiles(n_features=2, n_classes=3)\n",
        "plt.scatter(X1[:, 0], X1[:, 1], marker=\"o\", c=Y1, s=25, edgecolor=\"k\")"
      ],
      "metadata": {
        "id": "9jlPqxHw2u_i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Desarrollo\n",
        "\n",
        "Si puede ver este archivo, significa que ya se cumplió\n",
        "\"1. Crear un Jupyter Notebook para llevar a cabo el laboratorio\"."
      ],
      "metadata": {
        "id": "2izpKANa3faK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Paso 1: Obtención de datos.\n",
        "\n",
        "Para que se cumpla el paso 1, se debe completar el punto 2 de la tarea de generar el conjunto de datos artificial que siga una distribución Gaussiana concéntrica.\n",
        "\n",
        "Primero, me gusta dejar la importación de las librerías a utilizar en su propio bloque.\n",
        "\n",
        "Luego de esto, se \"importarán\" los datos."
      ],
      "metadata": {
        "id": "ocPjE4_J6Wnx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ktAjG53v2sGv"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import make_gaussian_quantiles #I guess this is to obtain the data.\n",
        "import matplotlib.pyplot as plt # Plots!\n",
        "import numpy as np # Linear algebra."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora se generarán los datos, estos deben seguir una distribución gaussiana concéntrica."
      ],
      "metadata": {
        "id": "u0aUtOYM7oY-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Generate 2D normally distributed data\n",
        "X, Y = make_gaussian_quantiles(cov=2., n_samples=1000, n_features=2, n_classes=2\n",
        "                               , random_state=1902)"
      ],
      "metadata": {
        "id": "78TSCOKS8Bq1"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Con esto hecho, se cumple el punto: \"2. Genera un conjunto de datos artificial que siga una distribución Gaussiana concéntrica\"."
      ],
      "metadata": {
        "id": "RH8WnpQu8Vgg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Paso 2: Manipulación de datos.\n",
        "\n",
        "El siguiente paso es de la manipulación de datos, donde se tomarán los sets de test, training y validation. Para esto necesitamos el método train_test_split de sklearn."
      ],
      "metadata": {
        "id": "r4a8GO3B8kCe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "Ldttbkei9atu"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora se procederá a hacer cada set.\n",
        "\n",
        "Si dividimos el 100% de los datos en 80% training y 20% test, podemos dividir nuevamente los datos de entrenamiento en 75% training y 25% validación.\n",
        "\n",
        "Como $0.25 × 0.8 = 0.2$, entonces el 20% de los datos totales quedan como validación, el 20% de los datos totales quedan de test y el 60% de los datos totales quedan de entrenamiento.\n",
        "\n",
        "Esto se logra llamando a train_test_split dos veces, a continuación."
      ],
      "metadata": {
        "id": "2ZmCbTlc9nA2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=1902)\n",
        "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.25, random_state=1902)"
      ],
      "metadata": {
        "id": "BbYLEhX79qWK"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Con esto, la manipulación de datos está completa y el punto \"3. Divide el conjunto de datos en conjuntos de entrenamiento, prueba y validación\"."
      ],
      "metadata": {
        "id": "TgTtEfzVAAoi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Paso 3: Exploración\n",
        "\n"
      ],
      "metadata": {
        "id": "5s6uJcD9AURe"
      }
    }
  ]
}